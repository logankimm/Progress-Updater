{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import json\n",
    "import os\n",
    "import sqlite3\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import urllib.request\n",
    "import csv\n",
    "from google_apis.sheets import Sheets_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize global variables\n",
    "SHEET_ID = \"\"\n",
    "PREV_PLAYED = \"\"\n",
    "AIMLAB_DB_PATH = os.path.abspath(os.path.join(os.getenv(\"APPDATA\"), os.pardir, \"LocalLow\\\\statespace\\\\aimlab_tb\\\\klutch.bytes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_config():\n",
    "    try:\n",
    "        with open(\"./config.json\", \"r\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "        \n",
    "        last_played = datetime.strptime(json_data[\"scenario_data\"][\"last_played\"], \"%Y-%m-%d %H:%M:%S\")\n",
    "        SHEET_ID = json_data[\"sheets\"][\"id\"]\n",
    "        cs_level_ids = None\n",
    "\n",
    "        # Match scenario difficulty\n",
    "        difficulty = json_data[\"scenario_data\"][\"playlist_type\"].lower()\n",
    "        match difficulty:\n",
    "            case \"beginner\":\n",
    "                cs_level_ids = json_data[\"scenario_data\"][\"beginner_scenarios\"]\n",
    "            case \"intermediate\":\n",
    "                cs_level_ids = json_data[\"scenario_data\"][\"intermediate_scenarios\"]\n",
    "            case _:\n",
    "                print(\"Invalid playlist type\")\n",
    "                raise ValueError\n",
    "    except:\n",
    "        print(\"Invalid json file\")\n",
    "        raise ValueError\n",
    "    return (json_data, last_played, SHEET_ID, cs_level_ids)\n",
    "\n",
    "config_data, PREV_PLAYED, SHEET_ID, cs_level_ids = parse_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Google API to do stuff with\n",
    "def initalize_apis(spread_id):\n",
    "    SCOPES = [\n",
    "        \"https://www.googleapis.com/auth/spreadsheets\",\n",
    "    ]\n",
    "\n",
    "    # When there is pre-determined credentials/token path already\n",
    "    sheet = Sheets_API(scopes = SCOPES, ID = spread_id)\n",
    "    return sheet\n",
    "\n",
    "sheet = initalize_apis(spread_id = SHEET_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_config(json_data):\n",
    "    with open(\"config.json\", \"w\") as jsonFile:\n",
    "        json.dump(config_data, jsonFile, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing data to see if the row updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sheets_API' object has no attribute 'update_scenario'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# starting from whatever the earliest row is - update through\u001b[39;00m\n\u001b[0;32m      2\u001b[0m test_data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m53\u001b[39m, \u001b[38;5;241m14\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m \u001b[43msheet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_scenario\u001b[49m(test_data, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sheets_API' object has no attribute 'update_scenario'"
     ]
    }
   ],
   "source": [
    "# starting from whatever the earliest row is - update through\n",
    "test_data = [12, 53, 14]\n",
    "sheet.update_scenario(test_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open db connection\n",
    "con = sqlite3.connect(AIMLAB_DB_PATH)\n",
    "cur = con.cursor()\n",
    "\n",
    "# Get scores from the database\n",
    "for scenario_index, item in enumerate(cs_level_ids.items()):\n",
    "    csid, name = item\n",
    "    \n",
    "    # Query for new data to add\n",
    "    cur.execute(\n",
    "        f\"SELECT score, endedAt FROM TaskData WHERE taskName = ? AND endedAt > date(?) ORDER BY endedAt\",\n",
    "        [csid, PREV_PLAYED])\n",
    "    result = cur.fetchall()\n",
    "\n",
    "    # Update the last played within config file\n",
    "    config_data[\"scenario_data\"][\"last_played\"] = result[-1][1]\n",
    "    update_config(config_data)\n",
    "\n",
    "    update_data = parse_query(result)\n",
    "    \n",
    "    # Update Sheet\n",
    "    sheet.update_scenario(values, scenario_index, len(values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_query(result)\n",
    "    error_offset, parsed_values = 0, []\n",
    "\n",
    "    # iterate through in chunks of 3\n",
    "    for i in range(len(result)):\n",
    "\n",
    "        # Every 3 indicies create an interval for the day\n",
    "        if (i % 3) == 2 - error_offset:\n",
    "\n",
    "            # Check if dates of beginning and end of interval have same date\n",
    "            if result[i - 2][1][:10] != result[i][1][:10]:\n",
    "                errors = 1\n",
    "                # Check if middle scenario was also corrupted\n",
    "                if result[i - 2][1][:10] != result[i - 1][1][:10]:\n",
    "                    errors += 1\n",
    "                \n",
    "                # Update error offset\n",
    "                error_offset += errors\n",
    "                \n",
    "            # Compute the intervals for the day\n",
    "            row_data = result[i - 2:i + 1 - errors]\n",
    "            scores = [x[0] for x in row_data]\n",
    "            parsed_values.append(scores)\n",
    "        \n",
    "    return parsed_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 1, 22, 18, 33, 42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = \"2024-01-22 18:33:42\"\n",
    "a = datetime.strptime(da, \"%Y-%m-%d %H:%M:%S\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(495, '2024-01-13 00:59:08'),\n",
       " (551, '2024-01-13 01:00:19'),\n",
       " (512, '2024-01-13 01:01:27'),\n",
       " (639, '2024-01-14 03:09:21'),\n",
       " (607, '2024-01-14 03:10:27'),\n",
       " (588, '2024-01-14 03:11:38'),\n",
       " (553, '2024-01-15 02:56:15'),\n",
       " (691, '2024-01-15 02:57:32'),\n",
       " (659, '2024-01-15 02:58:38'),\n",
       " (620, '2024-01-16 13:09:16'),\n",
       " (617, '2024-01-16 13:10:26'),\n",
       " (665, '2024-01-16 13:11:37'),\n",
       " (585, '2024-01-17 13:13:58'),\n",
       " (636, '2024-01-17 13:15:06'),\n",
       " (669, '2024-01-17 13:16:13'),\n",
       " (607, '2024-01-18 12:12:00'),\n",
       " (626, '2024-01-18 12:13:06'),\n",
       " (691, '2024-01-19 13:14:13'),\n",
       " (662, '2024-01-19 13:15:19'),\n",
       " (708, '2024-01-19 13:16:25'),\n",
       " (588, '2024-01-20 15:19:23'),\n",
       " (604, '2024-01-20 15:20:32'),\n",
       " (525, '2024-01-20 15:21:38'),\n",
       " (591, '2024-01-21 13:33:56'),\n",
       " (669, '2024-01-21 13:35:04'),\n",
       " (646, '2024-01-21 13:36:10'),\n",
       " (601, '2024-01-22 18:28:09'),\n",
       " (653, '2024-01-22 18:29:15'),\n",
       " (611, '2024-01-22 18:30:21')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\n",
    "    f\"SELECT score, endedAt FROM TaskData WHERE taskName = ? AND endedAt > date(?) ORDER BY endedAt\",\n",
    "    [\"CsLevel.Lowgravity56.VT Dynam.RQCD1Z\", PREV_PLAYED])\n",
    "error_res = cur.fetchall()\n",
    "error_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[495, 551, 512]\n",
      "[639, 607, 588]\n",
      "[553, 691, 659]\n",
      "[620, 617, 665]\n",
      "[585, 636, 669]\n",
      "[607, 626]\n",
      "[691, 662, 708]\n",
      "[588, 604, 525]\n",
      "[591, 669, 646]\n",
      "[601, 653, 611]\n"
     ]
    }
   ],
   "source": [
    "# error correction on the result\n",
    "values, temp = [], []\n",
    "error_offset = 0\n",
    "\n",
    "# iterate through in chunks of 3\n",
    "for i in range(len(error_res)):\n",
    "\n",
    "    # every 3 check if a scenario wasn't accounted for\n",
    "    if (i % 3) == 2 - error_offset:\n",
    "\n",
    "        errors = 0\n",
    "        # Check if dates of beginning and end of interval have same date\n",
    "        # print(error_res[i - 2][1][:10], error_res[i][1][:10])\n",
    "        if error_res[i - 2][1][:10] != error_res[i][1][:10]:\n",
    "            errors += 1\n",
    "            # Check if middle scenario was also corrupted\n",
    "            if error_res[i - 2][1][:10] != error_res[i - 1][1][:10]:\n",
    "                errors += 1\n",
    "            \n",
    "            # Update error offset\n",
    "            error_offset += errors\n",
    "            \n",
    "        # Add as many 0s as there are errors to current batch\n",
    "        # Compute the intervals for the day\n",
    "        row_data = result[i - 2:i + 1 - errors]\n",
    "        scores = [x[0] for x in row_data]\n",
    "        values.append(scores)\n",
    "    #     # sheet.update_scenario(scores, index)\n",
    "    # print(scores, scenario_index, len(values))\n",
    "    #     Add current day to values and reset day counter\n",
    "    #     values.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CsLevel.VT Empyrean.VT Angle.RB668Z': 'VT Angleshot Novice',\n",
       " 'CsLevel.Lowgravity56.VT x WHJ.RWEZ9J': 'VT x WHJ Smooth Strafe Sphere',\n",
       " 'CsLevel.Lowgravity56.VT Adjus.ROJETY': 'VT Adjust Track VALORANT',\n",
       " 'CsLevel.Lowgravity56.VT 3T Wi.RTA5MX': 'VT 3T Wide',\n",
       " 'CsLevel.Lowgravity56.VT Berry.RUPUHP': 'VT berryTS Static Small',\n",
       " 'CsLevel.Lowgravity56.VT x WHJ.RWFB5F': 'VT x WHJ 5 Sphere Hipfire Small',\n",
       " 'CsLevel.VT Empyrean.VT 1w2ts.R21FUT': 'VT 1w2ts Smallflicks VALORANT',\n",
       " 'CsLevel.Lowgravity56.VT Dynam.RQCD1Z': 'VT Dynamic Reflex Micro',\n",
       " 'CsLevel.Lowgravity56.VT x WHJ.RWFQU4': 'VT x WHJ Speedswitch Click'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'data.csv'\n",
    "cs_level_ids = dict()\n",
    "blacklist = dict()\n",
    "\n",
    "# Open and read the CSV file\n",
    "with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "    # Create a CSV reader\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "\n",
    "    # Skip the header row\n",
    "    next(csv_reader)\n",
    "\n",
    "    # Iterate through the lines\n",
    "    for splits in csv_reader:\n",
    "        name = splits[0].replace('\"', '')\n",
    "        cs_level_id = splits[1].replace('\"', '')\n",
    "        cs_level_ids[cs_level_id] = name\n",
    "        date = datetime.strptime(splits[2].replace('\"', '').replace('\\n', ''), \"%d.%m.%Y\").date()\n",
    "        blacklist[name.lower()] = date\n",
    "\n",
    "cs_level_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
